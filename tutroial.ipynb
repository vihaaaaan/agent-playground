{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b064569c",
   "metadata": {},
   "source": [
    "# AI Agent Reference + Tutorial\n",
    "This notebook will be a reference/cheatsheet moving forward on different tools, strategies etc. when it comes to building out AI agents. This tutorial will primarily focus on utiltizing pure python rather than a particular framework for agentic development"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed199927",
   "metadata": {
    "vscode": {
     "languageId": "makefile"
    }
   },
   "source": [
    "## Basic OpenAI API Call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "74a233e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"id\": \"resp_082c7bb69ddab1db0068e418f0ee4481928afb3b4d4cf8247f\",\n",
      "  \"created_at\": 1759779056.0,\n",
      "  \"error\": null,\n",
      "  \"incomplete_details\": null,\n",
      "  \"instructions\": null,\n",
      "  \"metadata\": {},\n",
      "  \"model\": \"gpt-4o-2024-08-06\",\n",
      "  \"object\": \"response\",\n",
      "  \"output\": [\n",
      "    {\n",
      "      \"id\": \"msg_082c7bb69ddab1db0068e418f1e1d88192b8e5d7835d226f2d\",\n",
      "      \"content\": [\n",
      "        {\n",
      "          \"annotations\": [],\n",
      "          \"text\": \"Under a shimmering moonlit sky, the gentle unicorn whispered dreams of stardust to the sleeping woodland creatures, filling their night with magic and peace.\",\n",
      "          \"type\": \"output_text\",\n",
      "          \"logprobs\": []\n",
      "        }\n",
      "      ],\n",
      "      \"role\": \"assistant\",\n",
      "      \"status\": \"completed\",\n",
      "      \"type\": \"message\"\n",
      "    }\n",
      "  ],\n",
      "  \"parallel_tool_calls\": true,\n",
      "  \"temperature\": 1.0,\n",
      "  \"tool_choice\": \"auto\",\n",
      "  \"tools\": [],\n",
      "  \"top_p\": 1.0,\n",
      "  \"background\": false,\n",
      "  \"max_output_tokens\": null,\n",
      "  \"max_tool_calls\": null,\n",
      "  \"previous_response_id\": null,\n",
      "  \"reasoning\": {\n",
      "    \"effort\": null,\n",
      "    \"summary\": null\n",
      "  },\n",
      "  \"service_tier\": \"default\",\n",
      "  \"status\": \"completed\",\n",
      "  \"text\": {\n",
      "    \"format\": {\n",
      "      \"type\": \"text\"\n",
      "    },\n",
      "    \"verbosity\": \"medium\"\n",
      "  },\n",
      "  \"top_logprobs\": 0,\n",
      "  \"truncation\": \"disabled\",\n",
      "  \"usage\": {\n",
      "    \"input_tokens\": 18,\n",
      "    \"input_tokens_details\": {\n",
      "      \"cached_tokens\": 0\n",
      "    },\n",
      "    \"output_tokens\": 31,\n",
      "    \"output_tokens_details\": {\n",
      "      \"reasoning_tokens\": 0\n",
      "    },\n",
      "    \"total_tokens\": 49\n",
      "  },\n",
      "  \"user\": null,\n",
      "  \"billing\": {\n",
      "    \"payer\": \"developer\"\n",
      "  },\n",
      "  \"prompt_cache_key\": null,\n",
      "  \"safety_identifier\": null,\n",
      "  \"store\": true\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "import json\n",
    "client = OpenAI()\n",
    "\n",
    "response = client.responses.create(\n",
    "    model=\"gpt-4o\",\n",
    "    input=\"Write a one-sentence bedtime story about a unicorn.\"\n",
    ")\n",
    "formatted_response = json.dumps(response.to_dict(), indent=2)\n",
    "print(formatted_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c42552a4",
   "metadata": {},
   "source": [
    "## Structured Outputs \n",
    "You can use pydantic objects in order to have the LLMs response conform to a specific schema. This allows for more meaningful interactions with LLMs where they can create real data objects beyond simply returning text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2f6d2e75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"user\": \"Vihaan\",\n",
      "  \"task_name\": \"Complete Book Report on Percy Jackson and the Lightning Thief\",\n",
      "  \"description\": \"Report should be at least 1000 words long and include a summary of the book, character analysis, and personal reflections on the story.\",\n",
      "  \"deadline\": \"2023-10-13\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from datetime import date\n",
    "\n",
    "class ToDoItem(BaseModel):\n",
    "    user: str = Field(..., description=\"The user who created the task\")\n",
    "    task_name: str = Field(..., description=\"The name of the task\")\n",
    "    description: str = Field(..., description=\"A brief description of the task\")\n",
    "    deadline: date = Field(..., description=\"When the task is due\")\n",
    "\n",
    "# Grab current date to inject into prompts when provided relative dates\n",
    "today = date.today().isoformat()\n",
    "# Prompt\n",
    "content = f\"Vihaan needs to complete a book report on Percy Jackson and the Lightning Thief by next Friday. The report should be at least 1000 words long and include a summary of the book, character analysis, and personal reflections on the story.\"\n",
    "# OpenAI API call to parse the content into a structured ToDoItem\n",
    "response = client.responses.parse(\n",
    "    model=\"gpt-4o-2024-08-06\",\n",
    "    input=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"You are a helpful assistant that creates structured to-do items when given a description of one in natural language.  In order to calculate relative dates, note that the current date is {today}\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": content,\n",
    "        }\n",
    "    ],\n",
    "    text_format=ToDoItem\n",
    ")\n",
    "\n",
    "todo_item = response.output_parsed\n",
    "print(json.dumps(todo_item.model_dump(), indent=2, default=str))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5ca2261",
   "metadata": {},
   "source": [
    "## Testing Structured Outputs with Sets of Literals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65deef5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"name\": \"ClearGrid\",\n",
      "  \"industry\": \"finance\",\n",
      "  \"num_employees\": 0,\n",
      "  \"headquarters\": \"\",\n",
      "  \"founded_year\": 0\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "from typing import Literal, List\n",
    "from pydantic import BaseModel, Field\n",
    "from enum import StrEnum\n",
    "\n",
    "class DealFlowFinancingRound(StrEnum):\n",
    "    Healthcare = \"healthcare\"\n",
    "    Finance = \"finance\"\n",
    "    Biotech = \"biotech\"\n",
    "    SupplyChain = \"supply-chain\"\n",
    "\n",
    "class CompanyInfo(BaseModel):\n",
    "    name: str = Field(..., description=\"The name of the company\")\n",
    "    # industry: Literal[\"healthcare\", \"AI\", \"finance\", \"biotech\"] = Field(..., description=\"The industry the company operates in\")\n",
    "    industry: DealFlowFinancingRound = Field(..., description=\"The industry the company operates in\")\n",
    "    num_employees: int = Field(..., description=\"The number of employees in the company\")\n",
    "    headquarters: str = Field(..., description=\"The location of the company's headquarters\")\n",
    "    founded_year: int = Field(..., description=\"The year the company was founded\")\n",
    "\n",
    "content = f'''From: Daniel Park <daniel@peakvc.com\n",
    ">\n",
    "To: Vihaan Vulpala <vihaan@lioncrest.vc\n",
    ">\n",
    "Cc: Evan Li <evan@cleargrid.io\n",
    ">\n",
    "Subject: Quick intro — Evan Li @ ClearGrid (supply-chain ML)\n",
    "\n",
    "Vihaan — quick intro to Evan Li, founder of ClearGrid, building ML models that predict supplier-level disruptions (30–60 day horizon). Evan has early revenue ($80k ARR) with two regional distributors and is raising $2M seed. I thought this maps to your portfolio. Evan — Vihaan leads enterprise/data at Lioncrest. Would you be open to a 20–30 min intro? — Daniel '''\n",
    "response = client.responses.parse(\n",
    "    model=\"gpt-4o-2024-08-06\",\n",
    "    input=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"You are a helpful assistant helps VCs extract data from unstructured text such as emails. conversations, documents etc.\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": content,\n",
    "        }\n",
    "    ],\n",
    "    text_format=CompanyInfo\n",
    ")\n",
    "\n",
    "todo_item = response.output_parsed\n",
    "print(json.dumps(todo_item.model_dump(), indent=2, default=str))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e14b1df7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cbe9923a",
   "metadata": {},
   "source": [
    "# Tool Calling \n",
    "Now we're getting into the good stuff. Tools--[according Anthropic at least](https://www.anthropic.com/engineering/building-effective-agents#:~:text=Building%20blocks%2C%20workflows%2C%20and%20agents)--are one of the three fundemental building blocks of constructing AI agents (the other two being retrieval and memory). \n",
    "\n",
    "Tools allow agents to take action in the world—they’re how an LLM moves beyond just generating text and actually does something. Whether it’s calling an API, querying a database, sending an email, or triggering a workflow, tools are what make an agent useful, interactive, and capable of solving real problems. \n",
    "\n",
    "At it's core tool calling has a few standard steps. Let's walk through through them. Follow along in the code with the same numbers:\n",
    "1. **Defining the tool:** Write a function for each tool you want the LLM to be able to call + a python dict containing the tool's name, a description, and a schema for arguments that the tool needs in order to be called. \n",
    "2. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4efd2a6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The current temperature in San Francisco is 13.2°C.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "# STEP 1: Define tool\n",
    "\n",
    "# Need both a function...\n",
    "def get_weather(lat: int, long: int):\n",
    "    \"\"\"\n",
    "    Get the current weather for a given city.\n",
    "    \"\"\"\n",
    "    response = requests.get(f\"https://api.open-meteo.com/v1/forecast?latitude={lat}&longitude={long}&current=temperature_2m,wind_speed_10m&hourly=temperature_2m,relative_humidity_2m,wind_speed_10m\")\n",
    "    data = response.json()\n",
    "    return data['current']['temperature_2m']\n",
    "\n",
    "# ...and a dict describing the tool\n",
    "# This dict is what the LLM will use to understand how to call the function\n",
    "tools = [{\n",
    "        \"type\": \"function\",\n",
    "        \"name\": \"get_weather\",\n",
    "        \"description\": \"Get current temperature for provided coordinates in celsius.\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"latitude\": {\"type\": \"number\"},\n",
    "                \"longitude\": {\"type\": \"number\"}\n",
    "            },\n",
    "            \"required\": [\"latitude\", \"longitude\"],\n",
    "            \"additionalProperties\": False\n",
    "        },\n",
    "        \"strict\": True\n",
    "    }]   \n",
    "\n",
    "# STEP 2: Call the LLM with the tool\n",
    "input_messages = [{\"role\": \"user\", \"content\": \"Whats the weather like in San Francisco?\"}]\n",
    "\n",
    "\n",
    "response = client.responses.create(\n",
    "    model=\"gpt-4.1\",\n",
    "    input=input_messages,\n",
    "    tools=tools,\n",
    ")\n",
    "\n",
    "# STEP 3: Parse the response and process tool call\n",
    "response_type = response.output[0].type\n",
    "if response_type == \"function_call\":\n",
    "    if response.output[0].name == \"get_weather\":\n",
    "        # Extract the arguments for the function call\n",
    "        args = json.loads(response.output[0].arguments)\n",
    "        latitude = args[\"latitude\"]\n",
    "        longitude = args[\"longitude\"]\n",
    "        \n",
    "        # Call the function with the extracted arguments\n",
    "        weather = get_weather(latitude, longitude)\n",
    "        \n",
    "        # Print the weather information\n",
    "        print(f\"The current temperature in San Francisco is {weather}°C.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fa6ab2c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "752a8c0b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4faa8ddb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26766e89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a70a6ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c596203",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8a95234e",
   "metadata": {},
   "source": [
    "You make think that some of the utility that tool calling provides is redundant with sctructured outputs. However, where tool calling truly stands out is providing optionality to the LLM. Allowing to decide what tools it wants to call when. Here's a more complex example illustrating that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df3aa3a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 1: Define the tool\n",
    "# Here we'll define four possible tools for our to-do list application:\n",
    "# 1. Add a new task\n",
    "# 2. Breaking it down into subtasks\n",
    "# 3. Obtaining resources related to the task\n",
    "\n",
    "tasks = []\n",
    "\n",
    "class ToDoItem(BaseModel):\n",
    "    task_name: str = Field(..., description=\"The name of the task\")\n",
    "    description: str = Field(..., description=\"A brief description of the task\")\n",
    "    deadline: date = Field(..., description=\"When the task is due\")\n",
    "    subtasks: list[ToDoItem] = Field(default_factory=list, description=\"List of subtasks\")\n",
    "\n",
    "def add_task(item: ToDoItem):\n",
    "    # Simulate creating a task in a database or API\n",
    "    print(f\"Creating task: {item.task_name} with description: {item.description} and deadline: {item.deadline}\")\n",
    "    tasks.append(item)\n",
    "    return {\"status\": \"success\", \"current_task_list\": [t.model_dump() for t in tasks]}\n",
    "\n",
    "def break_down_task(subtask_prompt_list: list[str]):\n",
    "    pass\n",
    "\n",
    "tools = {\n",
    "    \"add_task\": {\n",
    "        \"name\": \"add_task\",\n",
    "        \"description\": \"Add a new task to the to-do list.\",\n",
    "        \"parameters\": ToDoItem.model_json_schema(),\n",
    "        \"function\": add_task\n",
    "    },\n",
    "    \"break_down_task\": {\n",
    "        \"name\": \"break_down_task\",\n",
    "        \"description\": \"Break down a task into subtasks.\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"subtask_prompt_list\": {\n",
    "                    \"type\": \"array\",\n",
    "                    \"items\": {\"type\": \"string\"},\n",
    "                    \"description\": \"List of subtasks to be created.\"\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\"subtask_prompt_list\"]\n",
    "        },\n",
    "        \"function\": break_down_task\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "system_prompt = \"\"\"\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "def process(user_prompt: str):\n",
    "    response = client.responses.create(\n",
    "        model=\"gpt-4o\",\n",
    "        input=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": system_prompt\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": user_prompt\n",
    "             },\n",
    "        ],å\n",
    "        tools=tools,\n",
    "        tool_choice=\"auto\", \n",
    "    )\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
